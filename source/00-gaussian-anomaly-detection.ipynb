{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Anomaly Detection\n",
    "\n",
    "Detecting anomalies with data using Gaussian data assumptions is a simple but often effective technique.\n",
    "In this notebook we explore the basics of anomaly detection with some Gaussian data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from functools import reduce\n",
    "from scipy.stats import norm\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "alt.renderers.enable('notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online mean and variance estimates\n",
    "\n",
    "The following class uses [Chan's formula](https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Parallel_algorithm) for online mean and variance estimates, so that we can calculate estimated mean and variance in a single pass over a large data set, and parallelize over partitioned data.\n",
    "\n",
    "In this lab, we will not cover the details of how efficient streaming moments operate: the important takeaway is that obtaining means and variances from data for fitting Gaussian distributions is fast and efficient, and so it can be a useful tool in the anomaly detection toolbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "from detail.streamingmoments import StreamingMoments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and Moments\n",
    "\n",
    "In the following cell we generate some Gaussian data, simulating data that we might collect from systems, users or the outside world.\n",
    "\n",
    "We use our `StreamingMoments` class to get the mean and variance of the data. The data is generated in multiple independent partitions, to demonstrate that streaming moments can be computed across partitions and merged to get a global result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some data divided into multiple paritions\n",
    "data_partitions = [norm.rvs(0, 1, size=10000) for x in range(10)]\n",
    "\n",
    "# Sketch the moments of each partition, and then merge the sketches to a final result\n",
    "moments = reduce(lambda m1, m2: m1.merge_from(m2), \\\n",
    "                 [StreamingMoments() << p for p in data_partitions], \\\n",
    "                 StreamingMoments())\n",
    "\n",
    "print(\"count= %d  mean= %.2f  variance= %.2f\" % (moments.count, moments.mean(), moments.variance()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Gaussian Anomaly Detector\n",
    "\n",
    "In the following cell we define a class for doing anomaly detection, assuming Gaussian data. You can see that this class defines two example anomaly score methods. These two scores will be explored and compared below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianAnomalyDetector(object):\n",
    "    def __init__(self, mean, variance):\n",
    "        self.mean = mean\n",
    "        self.stdv = math.sqrt(variance)\n",
    "\n",
    "    # take the \"tail probabilility\" as the anomaly score\n",
    "    def anomaly1(self, x):\n",
    "        cdf = norm.cdf(x, self.mean, self.stdv)\n",
    "        # find the smallest tail probability\n",
    "        anomaly = min(cdf, 1 - cdf)\n",
    "        return anomaly\n",
    "    \n",
    "    # use the negative log of the tail probability as the score\n",
    "    def anomaly2(self, x):\n",
    "        cdf = norm.cdf(x, self.mean, self.stdv)\n",
    "        # find the smallest tail probability\n",
    "        t = min(cdf, 1 - cdf)\n",
    "        # make sure we don't try to take the logarithm of zero\n",
    "        t = max(t, 1e-100)\n",
    "        return -math.log(2 * t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Detector\n",
    "\n",
    "The following cell creates an anomaly detector using the mean and variance we estimated from our example data.\n",
    "We also define some example data points that we can use to examine how our anomaly scores behave.\n",
    "\n",
    "Our data has a mean of zero and a standard deviation of 1, so our test data points span from zero to 8 standard deviations from the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = GaussianAnomalyDetector(moments.mean(), moments.variance())\n",
    "data = [0, -1, 2, -3, 4, -5, 6, -7, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Score 1\n",
    "\n",
    "First we will create a table of our test points and their anomaly scores using anomaly-score 1. Score 1 is simply the \"tail probability\": the probability mass to the right of our data, if it is greater than the mean, otherwise the mass of the tail to the left.\n",
    "\n",
    "Numerically, we can see two things: as we get farther from the mean, these scores get smaller.\n",
    "Therefore, for score 1, smaller values are \"more anomalous\".\n",
    "Additionally, we can see that these values become small very quickly, rapidly approaching zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores1 = pd.DataFrame({\n",
    "  'x': data,\n",
    "  'score1': [detector.anomaly1(x) for x in data]\n",
    "})\n",
    "scores1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Anomaly Score 1\n",
    "\n",
    "The following plot shows visually what we saw in the table: as values get farther from the mean, anomaly scores approach zero very fast. So comparing \"very anomalous\" values in an absolute sense will be difficult: the absolute difference between anomalous values will always be very close to zero as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alt.Chart(scores1).mark_line(point=True).encode(\n",
    "    x='x',\n",
    "    y='score1'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Score 2\n",
    "\n",
    "In this table we chart the values of anomaly score 2 for our test points. Anomaly score 2 is based on the negative logarithm of the \"tail probability\" this means that as data becomes \"more anomalous\", the score gets larger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores2 = pd.DataFrame({\n",
    "  'x': data,\n",
    "  'score2': [detector.anomaly2(x) for x in data]\n",
    "})\n",
    "scores2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Score 2\n",
    "\n",
    "When we plot the table above, we see that visually this score may be easier to work with. More anomalous values have larger anomaly scores, and comparing absolute scores is easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(scores2).mark_line(point=True).encode(\n",
    "    x='x',\n",
    "    y='score2'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "1. How would you choose an anomaly threshold for score 1?  Score 2?\n",
    "1. What other anomaly scores can you design, based on Gaussian distribution PDFs or CDFs?\n",
    "1. As the number of data samples you collect from a Gaussian distribution increases, how does the probability of a high anomaly score change?\n",
    "1. How do these Gaussian-based anomaly scores behave if they are given non-gaussian data?\n",
    "1. Can you adapt `GaussianAnomalyDetector` to use different distributions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
