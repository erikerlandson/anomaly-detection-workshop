{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extreme Values and Outliers\n",
    "When we collect samples, we may want to determine if values from our samples are somehow \"outliers\" - that is, anomalous - or if they are explainable by natural variations in the data.\n",
    "Answering this question can be tricky, but there is a branch of statistics called Extreme Value Statistics devoted to providing principled answers to this question.\n",
    "In this notebook we will explore how to apply Extreme Value Statistics (EVS) to the problem of distinguishing normal variations from anomalous outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats\n",
    "from scipy.stats import gamma\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from detail.altairdf import altairDF\n",
    "alt.renderers.enable(\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal Variation, or Outlier?\n",
    "Consider the following distribution, whose CDF is plotted below.\n",
    "Imagine that we took some samples, and want to know if the maximum value we measured is \"normal\" or an \"outlier\".\n",
    "\n",
    "In the cell below, our hypothetical maximum value is 10.\n",
    "We can see that 10 is out on the tail of our distribution, yet it is not outlandishly far out.\n",
    "In theory, any positive value _might_ be sampled from a Gamma distribution.\n",
    "\n",
    "Should we treat this value 10 as an outlier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotdf = altairDF(np.linspace(0, 20, num=20).tolist(), \\\n",
    "                  [lambda x: gamma.cdf(x, 1.)], \\\n",
    "                  labels = [\"gamma(1.0)\"], ycol=\"CDF\")\n",
    "chart = alt.Chart().mark_line().encode(x=\"x\", y=\"CDF\", color=\"color\")\n",
    "rule = alt.Chart().mark_rule(color=\"red\").encode(x='maximum:Q')\n",
    "alt.layer(chart, rule, data=plotdf).transform_calculate(maximum=\"10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of Sample Size\n",
    "Intuitively, we understand that the more samples we take, the more likely it is that we will measure \"larger\" values, just by chance.\n",
    "In the cells that follow, we take some samples from a distribution, find the maximum value, and then average these maximum values to get a sense of how increasing sample sizes might affect what kind of maximum values we measure.\n",
    "\n",
    "* What do you expect to happen as we increase sample size?\n",
    "* In the previous example, how does our judgement of whether our maximum value of 10 is an \"outlier\" or \"expected\" change, as our sample size changes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaging maximum values over samples size of 100\n",
    "sum([max(gamma.rvs(1.0, size=100)) for x in range(10)])/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaging maximum values over samples size of 1000\n",
    "sum([max(gamma.rvs(1.0, size=1000)) for x in range(10)])/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaging maximum values over samples size of 10000\n",
    "sum([max(gamma.rvs(1.0, size=10000)) for x in range(10)])/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extreme Value Distributions\n",
    "If we know the CDF of the distribution we are sampling from, it turns out that there is a simple formula that allows us to compute the CDF of a maximum, or \"extreme\" value from a sample of a given size.\n",
    "\n",
    "Define our sample size as `n`, and define the CDF of our data distribution as F(x).\n",
    "The probability that our maximum value is <= x is the probability that _all_ n of our samples are <= x, or:\n",
    "`F(x) * F(x) * ... F(x)` or simply `F(x)^n`\n",
    "\n",
    "In the following cells we define this function and use it to generate a table of values showing how this value changes as sample size increases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extremeCDF(x, n, cdf):\n",
    "    return math.pow(cdf(x), n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssv = [100, 1000, 10000, 100000]\n",
    "pd.DataFrame({\n",
    "    'ss': ssv,\n",
    "    'evCDF': [extremeCDF(10, ss, lambda x: gamma.cdf(x, 1.0)) for ss in ssv]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table above shows that our sample size has the effect our intuition expects: the larger the sample size, the more probable a given value is.\n",
    "For a largish sample size of 100000, sampling a maximum value of 10 is far more likely than if we only sample 100 values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Extreme Value Anomaly Score\n",
    "\n",
    "Since the Extreme Value has a well defined CDF, we can define an anomaly score using the same approach as we used previously for t-digests.\n",
    "In the next cell we declare an extreme value anomaly detector that returns the negative logarithm of the CDF tail.\n",
    "Here, the anomaly score depends on the sample size `n`, as well as the value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detail.tdigest import TDigest\n",
    "\n",
    "class ExtremeValueAnomalyDetector(object):\n",
    "    def __init__(self, td):\n",
    "        self.td = td\n",
    "    \n",
    "    def anomaly(self, xmax, n):\n",
    "        p = 1 - math.pow(self.td.cdf(xmax), n)\n",
    "        p = max(p, 1e-100)\n",
    "        return -math.log(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an Anomaly Detector\n",
    "To use our anomaly detector, we sketch our data with a t-digest and use it to instantiate a detector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sketch = TDigest(compression = 0.05)\n",
    "for x in gamma.rvs(1.0, size = 100000):\n",
    "    sketch.update(x)\n",
    "detector = ExtremeValueAnomalyDetector(sketch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Scores For Sample Sizes\n",
    "In the next cell we plot anomaly scores for different sample sizes.\n",
    "The plot provides visual confirmation that as sample sizes increase, any given extreme value becomes more likely to appear in our sample, and so its anomaly score is smaller:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotdf = altairDF(range(13), \\\n",
    "                  [lambda x: detector.anomaly(x, 100),lambda x: detector.anomaly(x, 1000),lambda x: detector.anomaly(x, 10000)], \\\n",
    "                  labels = [\"100\", \"1000\", \"10000\"], \\\n",
    "                  xcol=\"xmax\", ycol=\"anomaly-score\", ccol=\"sample-size\")\n",
    "alt.Chart(plotdf).mark_line(point=True,clip=True).encode(alt.Y('anomaly-score', scale=alt.Scale(domain=(0, 7))), x=\"xmax\", color=\"sample-size\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "1. Try generating an extreme value anomaly detector from a different data sketch\n",
    "1. As sample size approaches infinity, what happens to the probability of an anomalous extreme value?\n",
    "1. What are advantages and disadvantages of usin a sketch such as t-digest compared with a parametric distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
